{"cells":[{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"outputs_hidden":true}},"id":"9302ce7c-4946-4c42-b41e-b78dfa9fa93c"},{"cell_type":"code","source":["# All Possible Activities in Fabric: https://learn.microsoft.com/en-us/fabric/admin/operation-list"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2af92da2-cb66-4b8c-81b4-ae220568c607"},{"cell_type":"code","source":["from datetime import datetime, timedelta\n","import sempy_labs.admin as sla\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, TimestampType, BooleanType\n","\n","# Get the current date and time in UTC\n","yesterday_utc = datetime.utcnow()- timedelta(days=1)\n","start = datetime(yesterday_utc.year, yesterday_utc.month, yesterday_utc.day).strftime('%Y-%m-%dT%H:%M:%S')\n","end = (datetime(yesterday_utc.year, yesterday_utc.month, yesterday_utc.day) + timedelta(days=1) - timedelta(seconds=1)).strftime('%Y-%m-%dT%H:%M:%S')\n","\n","# Define the schema for the table\n","schema = StructType([\n","    StructField(\"id\", StringType(), True),\n","    StructField(\"record_type\", StringType(), True),\n","    StructField(\"creation_time\", TimestampType(), True),\n","    StructField(\"operation\", StringType(), True),\n","    StructField(\"organization_id\", StringType(), True),\n","    StructField(\"user_type\", StringType(), True),\n","    StructField(\"user_key\", StringType(), True),\n","    StructField(\"workload\", StringType(), True),\n","    StructField(\"result_status\", StringType(), True),\n","    StructField(\"user_id\", StringType(), True),\n","    StructField(\"client_ip\", StringType(), True),\n","    StructField(\"user_agent\", StringType(), True),\n","    StructField(\"activity\", StringType(), True),\n","    StructField(\"workspace_name\", StringType(), True),\n","    StructField(\"workspace_id\", StringType(), True),\n","    StructField(\"object_id\", StringType(), True),\n","    StructField(\"request_id\", StringType(), True),\n","    StructField(\"object_type\", StringType(), True),\n","    StructField(\"object_display_name\", StringType(), True),\n","    StructField(\"experience\", StringType(), True),\n","    StructField(\"refresh_enforcement_policy\", StringType(), True),\n","    StructField(\"is_success\", BooleanType(), True),\n","    StructField(\"activity_id\", StringType(), True),\n","    StructField(\"item_name\", StringType(), True),\n","    StructField(\"datset_name\", StringType(), True),\n","    StructField(\"report_name\", StringType(), True),\n","    StructField(\"capacity_id\", StringType(), True),\n","    StructField(\"capacity_name\", StringType(), True),\n","    StructField(\"app_name\", StringType(), True),\n","    StructField(\"dataset_id\", StringType(), True),\n","    StructField(\"report_id\", StringType(), True),\n","    StructField(\"artifact_id\", StringType(), True),\n","    StructField(\"artifact_name\", StringType(), True),\n","    StructField(\"report_type\", StringType(), True),\n","    StructField(\"app_report_id\", StringType(), True),\n","    StructField(\"distribution_method\", StringType(), True),\n","    StructField(\"consumption_method\", StringType(), True),\n","    StructField(\"artifact_kind\", StringType(), True),\n","])\n","\n","activities_df = sla.list_activity_events(start_time=start, end_time=end, activity_filter='ViewReport')\n","df = spark.createDataFrame(activities_df, schema)\n","\n","table_name = 'report_usage'\n","spark.sql(f\"delete from {table_name} where creation_time >= '{start}'\")\n","df.write.mode(\"append\").saveAsTable(table_name)\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"ad8d1cbd-e00b-4374-825b-72edd181e858"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"4d58ca4c-d03c-4c10-95ed-7f19718d293e","default_lakehouse_name":"test","default_lakehouse_workspace_id":"b7f472bb-a634-48fc-aa12-2d92331bd535"}}},"nbformat":4,"nbformat_minor":5}