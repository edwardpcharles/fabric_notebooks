{"cells":[{"cell_type":"markdown","source":["# Installing Semantic Link Labs"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ab5775ef-5fc4-4e72-b06d-60e3a997e4f8"},{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"outputs_hidden":true}},"id":"e859d847-486c-48bd-83d5-fd099645f107"},{"cell_type":"markdown","source":["## Defining Function for calling Refresh API"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"505ca07d-cf3a-40c8-a15a-42d2585c4c36"},{"cell_type":"code","source":["from typing import Optional\n","from uuid import UUID\n","from sempy_labs._helper_functions import (\n","    _base_api\n","    , resolve_dataset_from_report\n",")\n","\n","def resolve_dataset_refresh_enabled_from_report(\n","    report: str | UUID\n","    , report_workspace: Optional[str | UUID] = None\n",") -> bool:\n","\n","    \"\"\"\n","        Identifies if the dataset a report is linked to has its refresh enabled\n","\n","        This is a wrapper function for the following API: `Datasets - Get Refresh Schedule <https://learn.microsoft.com/en-us/rest/api/power-bi/datasets/get-refresh-schedule>`_.\n","\n","        Parameters\n","        ----------\n","        report : str | uuid.UUID\n","            The name or ID of the Power BI report.\n","        workspace : str | uuid.UUID, default=None\n","            The Fabric workspace name or ID in which the report exists.\n","            Defaults to None which resolves to the workspace of the attached lakehouse\n","            or if no lakehouse attached, resolves to the workspace of the notebook.\n","        Returns \n","        -------\n","        Boolean\n","            True or False if the Report's Refresh schedule is enabled\n","        \"\"\"\n","\n","    dataset_id = resolve_dataset_from_report(report=report, workspace=report_workspace)[0]\n","\n","    response = _base_api(\n","        request=f\"v1.0/myorg/datasets/{dataset_id}/refreshSchedule\"\n","    )\n","\n","    return response.json()[\"enabled\"]\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bd469c92-4c47-45b6-8061-d186262e8f8c"},{"cell_type":"markdown","source":["## Example Using Function"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8740b91a-916b-4bd6-b1f4-48624169364d"},{"cell_type":"code","source":["resolve_dataset_refresh_enabled_from_report(report='89f97405-6469-415e-9b21-1b540d12d786', report_workspace='29fa8608-7c01-4a50-ada1-3d8979109b64')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fb3a1a5e-6b86-4ef7-bb2f-2206f082afa0"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}