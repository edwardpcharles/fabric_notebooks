{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import sempy.fabric as fab\n","\n","def get_workspace_metadata(workspace_id: str) -> pd.DataFrame:\n","    \"\"\"\n","    Consolidates metadata (datasets, tables, columns, and measures)\n","    for all datasets within a specified workspace.\n","\n","    Args:\n","        workspace_id: The ID of the Microsoft Fabric workspace.\n","\n","    Returns:\n","        A pandas DataFrame with consolidated metadata.\n","    \"\"\"\n","    # 1. List all datasets in the workspace\n","    try:\n","        datasets = fab.list_datasets(workspace=workspace_id)\n","    except Exception as e:\n","        print(f\"Error listing datasets in workspace {workspace_id}: {e}\")\n","        return pd.DataFrame() # Return empty DataFrame on failure\n","\n","    all_metadata = []\n","\n","    # 2. Iterate through each dataset\n","    for _, dataset_row in datasets.iterrows():\n","        dataset_id = dataset_row['Dataset ID']\n","        dataset_name = dataset_row['Dataset Name']\n","\n","        print(f\"Processing Dataset: {dataset_name} ({dataset_id})\")\n","\n","        # 3. Get Tables and Columns for the current dataset\n","        try:\n","            tables = fab.list_tables(\n","                dataset=dataset_id,\n","                workspace=workspace_id,\n","                include_columns=True\n","            ).assign(\n","                MetadataType='Table/Column',\n","                DatasetId=dataset_id,\n","                DatasetName=dataset_name\n","            )\n","            # Rename for clarity and standardize\n","            if 'Column' not in tables.columns:\n","                tables['Column'] = None\n","            if 'Type' not in tables.columns:\n","                tables['Type'] = None\n","            tables = tables.rename(columns={'Name': 'TableName'})\n","            all_metadata.append(tables)\n","        except Exception as e:\n","            print(f\"  Warning: Could not list tables/columns for {dataset_name}. {e}\")\n","\n","        # 4. Get Measures for the current dataset\n","        try:\n","            measures = fab.list_measures(\n","                dataset=dataset_id,\n","                workspace=workspace_id\n","            ).assign(\n","                MetadataType='Measure',\n","                DatasetId=dataset_id,\n","                DatasetName=dataset_name,\n","                TableName=lambda x: x['Table Name'] # Keep existing TableName\n","            ).rename(columns={'Measure Name': 'MeasureName', 'Measure Expression':'Expression'}) # Rename Measure Name\n","            all_metadata.append(measures)\n","        except Exception as e:\n","            print(f\"  Warning: Could not list measures for {dataset_name}. {e}\")\n","\n","\n","    # 5. Concatenate all lists of tables/columns and measures\n","    if all_metadata:\n","        # Define a consistent set of columns for the final DataFrame\n","        final_columns = [\n","            'DatasetName', 'DatasetId', 'MetadataType',\n","            'TableName',\n","            'Column', 'Type', # Specific to Tables/Columns\n","            'MeasureName', 'Expression' # Specific to Measures\n","        ]\n","        \n","        # Concatenate and reindex to the common columns, filling missing values\n","        consolidated_df = pd.concat(all_metadata, ignore_index=True)\n","        return consolidated_df[\n","            consolidated_df.columns.intersection(final_columns)\n","        ].reindex(columns=final_columns)\n","    \n","    return pd.DataFrame()\n","\n","\n","# --- USAGE EXAMPLE ---\n","\n","# Note: You must replace this with your actual Workspace ID\n","WORKSPACE_ID = \"b1c1beef-4463-41b6-a24b-764acf8972f2\" \n","\n","# Run the function\n","metadata_df = get_workspace_metadata(WORKSPACE_ID)\n","\n","# Display the consolidated DataFrame\n","print(\"\\n--- Consolidated Metadata DataFrame ---\")\n","display(metadata_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"26573334-40f6-41ac-9688-ae3dbb72b373"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}